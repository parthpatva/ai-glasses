import cv2
import pyttsx3
import speech_recognition as sr
import threading
import time
from ultralytics import YOLO
import numpy as np

# Load YOLOv8n model
model = YOLO("yolov8n.pt")

# Initialize TTS
engine = pyttsx3.init()
engine.setProperty("rate", 170)

LANGUAGE = 'en'
MODE = 'help'

# Threaded video capture
class VideoCaptureThread:
    def __init__(self, src=0):
        self.cap = cv2.VideoCapture(src)
        self.ret, self.frame = self.cap.read()
        self.running = True
        self.thread = threading.Thread(target=self.update)
        self.thread.start()

    def update(self):
        while self.running:
            self.ret, self.frame = self.cap.read()

    def read(self):
        return self.ret, self.frame

    def stop(self):
        self.running = False
        self.thread.join()
        self.cap.release()

# TTS function
def speak(text):
    print("üó£Ô∏è", text)
    engine.say(text)
    engine.runAndWait()

# Listen function using speech_recognition (no PyAudio)
def listen_command(prompt_text="Say command"):
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        speak(prompt_text)
        print("Listening...")
        try:
            audio = recognizer.listen(source, timeout=5)
            command = recognizer.recognize_google(audio).lower()
            print("You said:", command)
            return command
        except sr.UnknownValueError:
            speak("Sorry, I didn't understand.")
            return ""
        except sr.RequestError:
            speak("Speech service error.")
            return ""
        except sr.WaitTimeoutError:
            speak("Listening timed out.")
            return ""

# Navigation logic
def get_navigation(detected_objects, frame_width):
    left_count = sum(1 for obj in detected_objects if obj[2] < frame_width // 3)
    right_count = sum(1 for obj in detected_objects if obj[3] > 2 * (frame_width // 3))

    if left_count == 0 and right_count == 0 and detected_objects:
        return "Move forward."
    elif left_count > right_count:
        return "Obstacle on the left. Move right."
    elif right_count > left_count:
        return "Obstacle on the right. Move left."
    elif detected_objects:
        return "Obstacle ahead. Stop."
    return "Path clear. Move forward."

# Object detection
def detect_objects(frame):
    results = model(frame, verbose=False)[0]
    detected = []

    for box in results.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        class_id = int(box.cls[0])
        label = model.names[class_id]
        detected.append((label, x1, x2))
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return frame, detected

# One-time help
def help_mode(frame):
    frame = cv2.resize(frame, (320, 240))
    frame, detected_objects = detect_objects(frame)
    nav_msg = get_navigation(detected_objects, frame.shape[1])

    if LANGUAGE == 'hi':
        translations = {
            "Obstacle on the left. Move right.": "‡§¨‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§¶‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§ú‡§æ‡§è‡§Ç‡•§",
            "Obstacle on the right. Move left.": "‡§¶‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§¨‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§ú‡§æ‡§è‡§Ç‡•§",
            "Obstacle ahead. Stop.": "‡§Ü‡§ó‡•á ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§∞‡•Å‡§ï ‡§ú‡§æ‡§ì‡•§",
            "Path clear. Move forward.": "‡§∞‡§æ‡§∏‡•ç‡§§‡§æ ‡§∏‡§æ‡§´ ‡§π‡•à‡•§ ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç‡•§",
            "Move forward.": "‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç‡•§"
        }
        nav_msg = translations.get(nav_msg, "‡§∞‡§æ‡§∏‡•ç‡§§‡§æ ‡§∏‡§æ‡§´ ‡§π‡•à‡•§")

    speak(nav_msg)
    cv2.imshow("Help Frame", frame)
    cv2.waitKey(2000)
    cv2.destroyWindow("Help Frame")

# Continuous switch mode
def switch_mode():
    video_stream = VideoCaptureThread(0)
    last_spoken = ""
    while True:
        ret, frame = video_stream.read()
        if not ret:
            break

        frame = cv2.resize(frame, (320, 240))
        frame, detected_objects = detect_objects(frame)
        nav_msg = get_navigation(detected_objects, frame.shape[1])

        if nav_msg != last_spoken:
            last_spoken = nav_msg
            if LANGUAGE == 'hi':
                translations = {
                    "Obstacle on the left. Move right.": "‡§¨‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§¶‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§ú‡§æ‡§è‡§Ç‡•§",
                    "Obstacle on the right. Move left.": "‡§¶‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§¨‡§æ‡§à‡§Ç ‡§ì‡§∞ ‡§ú‡§æ‡§è‡§Ç‡•§",
                    "Obstacle ahead. Stop.": "‡§Ü‡§ó‡•á ‡§¨‡§æ‡§ß‡§æ ‡§π‡•à‡•§ ‡§∞‡•Å‡§ï ‡§ú‡§æ‡§ì‡•§",
                    "Path clear. Move forward.": "‡§∞‡§æ‡§∏‡•ç‡§§‡§æ ‡§∏‡§æ‡§´ ‡§π‡•à‡•§ ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç‡•§",
                    "Move forward.": "‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç‡•§"
                }
                nav_msg = translations.get(nav_msg, "‡§∞‡§æ‡§∏‡•ç‡§§‡§æ ‡§∏‡§æ‡§´ ‡§π‡•à‡•§")

            threading.Thread(target=speak, args=(nav_msg,)).start()

        cv2.imshow("Switch Mode", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    video_stream.stop()
    cv2.destroyAllWindows()

# Main logic
def main():
    global LANGUAGE, MODE

    # 1. Language Selection
    lang_input = listen_command("Please say English or Hindi to choose your language.")
    LANGUAGE = 'hi' if "hindi" in lang_input else 'en'
    speak("You selected Hindi." if LANGUAGE == 'hi' else "You selected English.")
    speak("Hey! It's your AI guiding you to your path.")

    # Loop for help/switch selection
    while True:
        mode_input = listen_command("Please say help or switch to choose your mode.")
        MODE = 'help' if "help" in mode_input else 'switch'
        speak("Help mode activated." if MODE == 'help' else "Switch mode activated.")

        if MODE == 'help':
            cap = cv2.VideoCapture(0)
            ret, frame = cap.read()
            if ret:
                help_mode(frame)
            cap.release()

            follow_up = listen_command("Do you want to continue? Say yes or no.")
            if "yes" in follow_up:
                continue  # Re-ask mode
            else:
                speak("Repeating help mode.")
                continue
        else:
            switch_mode()
            break

if __name__ == "__main__":
    main()
