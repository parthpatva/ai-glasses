import cv2
import pyttsx3
import threading
import time
import speech_recognition as sr
from ultralytics import YOLO
import tempfile
import subprocess
import os

# Load YOLO model
model = YOLO("yolov8n.pt")

# Initialize Text-to-Speech
engine = pyttsx3.init()
engine.setProperty("rate", 170)

def speak(text):
    print("AI:", text)
    engine.say(text)
    engine.runAndWait()

# Record and recognize speech without PyAudio
def listen_command(prompt_text="Say command"):
    speak(prompt_text)
    print("Recording for 4 seconds...")

    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
        audio_path = f.name

    subprocess.run(['arecord', '-D', 'plughw:1', '-f', 'cd', '-t', 'wav', '-d', '4', '-r', '16000', audio_path])

    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio_data = recognizer.record(source)
        try:
            command = recognizer.recognize_google(audio_data).lower()
            print("Recognized:", command)
            return command
        except sr.UnknownValueError:
            speak("Sorry, I didn't catch that.")
        except sr.RequestError:
            speak("Speech recognition service failed.")
    return ""

class VideoCaptureThread:
    def __init__(self, source=0):
        self.cap = cv2.VideoCapture(source)
        self.ret, self.frame = self.cap.read()
        self.running = True
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.start()

    def update(self):
        while self.running:
            self.ret, self.frame = self.cap.read()

    def read(self):
        return self.ret, self.frame

    def stop(self):
        self.running = False
        self.thread.join()
        self.cap.release()

# Object detection

def detect_objects(frame):
    results = model(frame, verbose=False)
    detected_objects = []

    for result in results:
        for box in result.boxes[:3]:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            class_id = int(box.cls[0])
            label = model.names[class_id]
            detected_objects.append((label, x1, x2))
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return frame, detected_objects

# Navigation instructions

def get_navigation(detected_objects, width, language):
    left = sum(1 for obj in detected_objects if obj[1] < width // 3)
    right = sum(1 for obj in detected_objects if obj[2] > 2 * (width // 3))
    center = len(detected_objects) - left - right

    if center:
        return "Stop! Object ahead." if language == 'english' else "Rukiye! Aage badhaav hai."
    elif left > right:
        return "Move right." if language == 'english' else "Daiyen chaliye."
    elif right > left:
        return "Move left." if language == 'english' else "Baayen chaliye."
    else:
        return "Path is clear." if language == 'english' else "Raasta saaf hai."

def help_mode(language):
    video = VideoCaptureThread(0)
    time.sleep(1)
    ret, frame = video.read()
    if ret:
        frame = cv2.resize(frame, (320, 240))
        frame, detected_objects = detect_objects(frame)
        nav_msg = get_navigation(detected_objects, frame.shape[1], language)
        speak(nav_msg)
        cv2.imshow("Help Mode", frame)
        cv2.waitKey(2000)
        cv2.destroyAllWindows()
    video.stop()

def switch_mode(language):
    video = VideoCaptureThread(0)
    last_message = ""
    while True:
        ret, frame = video.read()
        if not ret:
            break

        frame = cv2.resize(frame, (320, 240))
        frame, detected_objects = detect_objects(frame)
        nav_msg = get_navigation(detected_objects, frame.shape[1], language)

        if nav_msg != last_message:
            last_message = nav_msg
            speak(nav_msg)

        cv2.imshow("Switch Mode", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    video.stop()
    cv2.destroyAllWindows()

def main():
    speak("Hey, it's your AI guiding you to your path.")

    # Language selection
    lang_input = listen_command("Please say English or Hindi to choose your language.")
    language = 'english' if 'english' in lang_input else 'hindi'
    speak("Language set to English." if language == 'english' else "Bhasha Hindi chuni gayi hai.")

    while True:
        mode_input = listen_command("Say help or switch to select the mode.")
        if 'help' in mode_input:
            speak("You selected help mode." if language == 'english' else "Aapne madad mode chuna hai.")
            help_mode(language)
            again = listen_command("Do you want help again? Say yes or no." if language == 'english' else "Kya aap fir se madad chahte hain? Haan ya na kahiye.")
            if 'no' in again:
                continue
        elif 'switch' in mode_input:
            speak("You selected switch mode." if language == 'english' else "Aapne dynamic mode chuna hai.")
            switch_mode(language)
        else:
            speak("Could not understand mode. Please say help or switch." if language == 'english' else "Kripya help ya switch kahiye.")

if __name__ == "__main__":
    main()
